{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "import numpy as np\n",
    "from halotools.sim_manager import CachedHaloCatalog, RockstarHlistReader, UserSuppliedPtclCatalog\n",
    "from helpers.readGadgetSnapshot import readGadgetSnapshot\n",
    "from AbundanceMatching import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the other catalog notebook, I'll be loading a catalog of halos then abundance matching them with a luminosity function. However, this time I'm loading a catalog that we have on disk at SLAC instead of one in the cloud. This will require one of Yao's other packages, [helpers](https://bitbucket.org/yymao/helpers/src). After it's loaded, I'll use [Yao's code](https://bitbucket.org/yymao/abundancematching) to do the abundance matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simname = 'chinchilla'\n",
    "Lbox = 400\n",
    "npart = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = 0.2\n",
    "a = 1/(1+z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HLIST_COLS = {'halo_id': (1, 'i8'), 'halo_upid': (6, 'i8'),\n",
    "              'halo_x': (17, 'f4'), 'halo_y': (18, 'f4'), 'halo_z': (19, 'f4'),\n",
    "              'halo_vx': (20, 'f4'), 'halo_vy': (21, 'f4'), 'halo_vz': (22, 'f4'),\n",
    "              'halo_mvir': (10, 'f4'), 'halo_rvir': (11, 'f4'), 'halo_rs':(12, 'f4'),\n",
    "              'halo_snapnum': (31, 'i8'),'halo_vpeak':(57, 'f8'), 'halo_halfmass_scale': (58, 'f4')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halo_finder = 'rockstar'\n",
    "\n",
    "#may also work for 1050 too.\n",
    "pmass = 1.44390e+08*((Lbox / 125.0) ** 3) * ((1024.0/npart)** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_cache_local = '' #UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_fnames = sorted(glob(loc + 'hlist_*.list'))  # snag all the hlists\n",
    "available_fnames = [fname[len(loc):] for fname in tmp_fnames]  # just want the names in the dir\n",
    "available_scale_factors = [float(fname[6:-5]) for fname in available_fnames]  # pull out scale factors\n",
    " \n",
    "idx = np.argmin(np.abs(np.array(available_scale_factors) - a))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fname = path.join(loc, available_fnames[idx])\n",
    "reader = RockstarHlistReader(fname, columns_to_keep, cache_filename, simname,\n",
    "                             halo_finder, z, version_name, Lbox, pmass,\n",
    "                             overwrite=True)\n",
    "reader.read_halocat(columns_to_convert, write_to_disk=True, update_cache_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_particles = '' #update\n",
    "all_particles = np.loadtxt(path_to_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptcl_catalog = UserSuppliedPtclCatalog(redshift=z, Lbox=Lbox, particle_mass=pmass,\\\n",
    "                                       x=all_particles[:,0], y=all_particles[:,1], z=all_particles[:,2])\n",
    "ptcl_cache_loc ='' #update\n",
    "ptcl_cache_filename = ptcl_cache_loc % (a, simname, version_name)  # make sure we don't have redunancies.\n",
    "ptcl_catalog.add_ptclcat_to_cache(ptcl_cache_filename, simname, version_name, 'p=%f'%p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've cached the halo catalog and the particles. You'll probably want to turn off the above cells (the two directly above this one and the one four above) as they only have to be run once. Now let's do the matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run me the first time only\n",
    "halocat = CachedHaloCatalog(path_to_cache_local, update_cached_fname=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#run me other times\n",
    "halocat = CachedHaloCatalog(simname = simname,halo_finder= halo_finder, redshift = z, version_name=version_name,dz_tol = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halocat.halo_table.colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading up a luminosity function. This one is from GAMA Survey, Loveday 2015 (got it from Joe). It is tweaked from the one from the other notebook to reflect the new redshfit range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lf = np.genfromtxt('lf_r_sersic_z_0.2_0.3.dat', skip_header=True)[:,1:3]\n",
    "#lf = np.genfromtxt('lf_r_sersic_z_0.1_0.2.dat', skip_header=True)[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_up_to = -6\n",
    "af = AbundanceFunction(lf[:use_up_to,0], lf[:use_up_to,1], (-27, -18),faint_end_fit_points = 7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.semilogy(lf[:,0], lf[:,1])\n",
    "x = np.linspace(-27, -18, 101)\n",
    "plt.semilogy(x, af(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print max(af(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter = 0.2\n",
    "remainder = af.deconvolute(scatter*LF_SCATTER_MULT, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, nd = af.get_number_density_table()\n",
    "plt.plot(x, remainder/nd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halos = np.array(halocat.halo_table)\n",
    "    \n",
    "nd_halos = calc_number_densities(halos['halo_vpeak'], halocat.Lbox[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_catalog = af.match(nd_halos, scatter*LF_SCATTER_MULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mag_cut = -18 \n",
    "valid_idxs = np.logical_and(~np.isnan(full_catalog), full_catalog <= mag_cut)\n",
    "catalog = full_catalog[valid_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(-1*catalog, bins = 30);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.savetxt('sham_catalog.npy', catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We want this plot to approximately match this one from Song. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_cat = np.genfromtxt('gama_z0.1_0.3_rband_absmag.ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mags = song_cat[song_cat[:,-1] > -10000,-1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(-1*catalog, bins = 30)\n",
    "plt.hist(-1*mags, bins = 30);\n",
    "plt.xlim([18,25]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#downsample here\n",
    "hist, bin_edges = np.histogram(-1*mags, bins = 30)\n",
    "downsample_idxs = set()\n",
    "makeshift_hist = []\n",
    "for idx, count in enumerate(hist):\n",
    "    low, high = bin_edges[idx:idx+2]\n",
    "    in_bin_idxs = np.where(np.logical_and(low <= -1*catalog, -1*catalog <= high))[0]\n",
    "    if in_bin_idxs.shape[0] <= count:\n",
    "        sampled_idxs = in_bin_idxs\n",
    "    else:\n",
    "        sampled_idxs = np.random.choice(in_bin_idxs, size = count, replace = False)\n",
    "\n",
    "    downsample_idxs = downsample_idxs | set(sampled_idxs)\n",
    "    \n",
    "downsampled_catalog = catalog[np.array(list(downsample_idxs), dtype=int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(-1*downsampled_catalog, bins = bin_edges)\n",
    "plt.hist(-1*mags, bins = bin_edges, alpha = 0.5);\n",
    "plt.xlim([18,25]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah! let's save the indexs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downsampled_idxs_array = np.zeros_like(valid_idxs, dtype=bool)\n",
    "counter = 0\n",
    "for idx, val in enumerate(valid_idxs):\n",
    "    if val:\n",
    "        if counter in downsample_idxs:\n",
    "            downsampled_idxs_array[idx] = True\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downsampled_idxs_array= np.where(valid_idxs)[0][np.array(list(downsample_idxs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(-1*full_catalog[downsampled_idxs_array], bins = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('gama_matched_catalog.npy', full_catalog)\n",
    "np.savetxt('gama_matched_catalog_idxs.npy', downsampled_idxs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
